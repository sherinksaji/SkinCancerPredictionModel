{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "69872a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "74a7b634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Path to the directory containing all images\n",
    "image_dir = 'HAM10000_images'\n",
    "\n",
    "# Path to the CSV file containing image labels\n",
    "metadata_path = 'HAM10000_metadata.csv'\n",
    "\n",
    "# Directories for the split datasets\n",
    "train_dir = 'train'\n",
    "test_dir = 'test'\n",
    "validation_dir = 'valid'\n",
    "\n",
    "# Creating directories if they don't exist\n",
    "for directory in [train_dir, test_dir, validation_dir]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9ca81e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         lesion_id      image_id     dx dx_type   age     sex localization   \n",
      "0      HAM_0000118  ISIC_0027419    bkl   histo  80.0    male        scalp  \\\n",
      "1      HAM_0000118  ISIC_0025030    bkl   histo  80.0    male        scalp   \n",
      "2      HAM_0002730  ISIC_0026769    bkl   histo  80.0    male        scalp   \n",
      "3      HAM_0002730  ISIC_0025661    bkl   histo  80.0    male        scalp   \n",
      "4      HAM_0001466  ISIC_0031633    bkl   histo  75.0    male          ear   \n",
      "...            ...           ...    ...     ...   ...     ...          ...   \n",
      "10010  HAM_0002867  ISIC_0033084  akiec   histo  40.0    male      abdomen   \n",
      "10011  HAM_0002867  ISIC_0033550  akiec   histo  40.0    male      abdomen   \n",
      "10012  HAM_0002867  ISIC_0033536  akiec   histo  40.0    male      abdomen   \n",
      "10013  HAM_0000239  ISIC_0032854  akiec   histo  80.0    male         face   \n",
      "10014  HAM_0003521  ISIC_0032258    mel   histo  70.0  female         back   \n",
      "\n",
      "       target  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n",
      "...       ...  \n",
      "10010       0  \n",
      "10011       0  \n",
      "10012       0  \n",
      "10013       0  \n",
      "10014       1  \n",
      "\n",
      "[10015 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load metadata\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "target=list(map(lambda x: 1 if x=='mel' else 0,metadata['dx']))\n",
    "metadata['target']=target\n",
    "print(metadata)\n",
    "# Splitting the dataset into train, validation, and test sets\n",
    "#train_val, test = train_test_split(metadata, test_size=0.2, random_state=42)\n",
    "#train, validation = train_test_split(train_val, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "baa9771e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'HAM10000_images\\\\ISIC_0030346.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Python310\\lib\\shutil.py:815\u001b[0m, in \u001b[0;36mmove\u001b[1;34m(src, dst, copy_function)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 815\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_dst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    816\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: 'HAM10000_images\\\\ISIC_0030346.jpg' -> 'train\\\\ISIC_0030346.jpg'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m         shutil\u001b[38;5;241m.\u001b[39mmove(source_path, target_path)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Moving the images\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[43mmove_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m move_images(validation, image_dir, validation_dir)\n\u001b[0;32m     13\u001b[0m move_images(test, image_dir, test_dir)\n",
      "Cell \u001b[1;32mIn[44], line 8\u001b[0m, in \u001b[0;36mmove_images\u001b[1;34m(df, source_dir, target_dir)\u001b[0m\n\u001b[0;32m      5\u001b[0m target_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(target_dir, filename)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Move the image\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\shutil.py:835\u001b[0m, in \u001b[0;36mmove\u001b[1;34m(src, dst, copy_function)\u001b[0m\n\u001b[0;32m    833\u001b[0m         rmtree(src)\n\u001b[0;32m    834\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 835\u001b[0m         \u001b[43mcopy_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_dst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m         os\u001b[38;5;241m.\u001b[39munlink(src)\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m real_dst\n",
      "File \u001b[1;32mc:\\Python310\\lib\\shutil.py:434\u001b[0m, in \u001b[0;36mcopy2\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dst):\n\u001b[0;32m    433\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(src))\n\u001b[1;32m--> 434\u001b[0m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    435\u001b[0m copystat(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "File \u001b[1;32mc:\\Python310\\lib\\shutil.py:254\u001b[0m, in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    252\u001b[0m     os\u001b[38;5;241m.\u001b[39msymlink(os\u001b[38;5;241m.\u001b[39mreadlink(src), dst)\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 254\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fsrc:\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    256\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dst, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[0;32m    257\u001b[0m                 \u001b[38;5;66;03m# macOS\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'HAM10000_images\\\\ISIC_0030346.jpg'"
     ]
    }
   ],
   "source": [
    "def move_images(df, source_dir, target_dir):\n",
    "    for _, row in df.iterrows():\n",
    "        filename = row['image_id'] + '.jpg'  # Assuming image IDs in the CSV and filenames match\n",
    "        source_path = os.path.join(source_dir, filename)\n",
    "        target_path = os.path.join(target_dir, filename)\n",
    "        \n",
    "        # Move the image\n",
    "        shutil.move(source_path, target_path)\n",
    "\n",
    "# Moving the images\n",
    "# move_images(train, image_dir, train_dir)\n",
    "# move_images(validation, image_dir, validation_dir)\n",
    "# move_images(test, image_dir, test_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec540cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "train_images = [f for f in os.listdir(train_dir) if os.path.isfile(os.path.join(train_dir, f))]\n",
    "test_images = [f for f in os.listdir(test_dir) if os.path.isfile(os.path.join(test_dir, f))]\n",
    "validation_images = [f for f in os.listdir(validation_dir) if os.path.isfile(os.path.join(validation_dir, f))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1093e829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_target_to_images(images):    \n",
    "    metadata_dict = pd.Series(metadata['dx'].values,index=metadata['image_id']).to_dict()\n",
    "    images_with_target = []\n",
    "    for image in images:\n",
    "        image_id = image.split('.')[0]  # Assuming image_id does not contain '.'\n",
    "        target = 1 if metadata_dict.get(image_id) == 'mel' else 0\n",
    "        train_image_with_label=(image,target)\n",
    "        images_with_target.append(train_image_with_label)\n",
    "    return images_with_target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eac4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_with_targets=append_target_to_images(train_images)\n",
    "test_images_with_targets=append_target_to_images(test_images)\n",
    "validation_images_with_targets=append_target_to_images(validation_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ccf232",
   "metadata": {},
   "outputs": [],
   "source": [
    "melanoma_count_in_train=sum(map(lambda x:x[1],train_images_with_targets))\n",
    "melanoma_count_in_test=sum(map(lambda x:x[1],test_images_with_targets))\n",
    "melanoma_count_in_validation=sum(map(lambda x:x[1],validation_images_with_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53b6b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Count of people with melanoma in train_images_with_targets:{melanoma_count_in_train}\")\n",
    "print(f\"Count of people without melanoma in train_images_with_targets:{len(train_images_with_targets)-melanoma_count_in_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17c4025",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Count of people with melanoma in test_images_with_targets:{melanoma_count_in_test}\")\n",
    "print(f\"Count of people without melanoma in test_images_with_targets:{len(test_images_with_targets)-melanoma_count_in_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fa6f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Count of people with melanoma in validation_images_with_targets:{melanoma_count_in_validation}\")\n",
    "print(f\"Count of people without melanoma in validation_images_with_targets:{len(validation_images_with_targets)-melanoma_count_in_validation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8776f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def move_on_class(imagelist,dirs):\n",
    "    for image_name, label in imagelist:\n",
    "        mel_dir = os.path.join(dirs, 'mel')\n",
    "        no_mel_dir = os.path.join(dirs, 'no_mel')\n",
    "        os.makedirs(mel_dir, exist_ok=True)\n",
    "        os.makedirs(no_mel_dir, exist_ok=True)\n",
    "        source_dir=dirs\n",
    "        # Determine the source path of the image\n",
    "        source_path = os.path.join(source_dir, image_name)\n",
    "\n",
    "        # Determine the destination path based on the label\n",
    "        if label == 1:  # Melanoma\n",
    "            dest_path = os.path.join(mel_dir, image_name)\n",
    "        else:  # Non-melanoma\n",
    "            dest_path = os.path.join(no_mel_dir, image_name)\n",
    "            \n",
    "\n",
    "        # Move the image from source to destination\n",
    "        shutil.move(source_path, dest_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac401b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#move_on_class(train_images_with_targets,'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f143352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#move_on_class(test_images_with_targets,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459e4d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#move_on_class(validation_images_with_targets,'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacfd1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Custom Gaussian Noise Transform\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "\n",
    "# Correctly ordered transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize the image\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # Adjust brightness and contrast\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip images horizontally\n",
    "    transforms.RandomRotation(20),  # Randomly rotate images by 20 degrees\n",
    "    transforms.ToTensor(),  # Convert PIL Image to Tensor\n",
    "    AddGaussianNoise(0., 0.1),  # Add custom Gaussian Noise\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the tensor\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cdea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "# Create datasets using ImageFolder\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "valid_dataset = datasets.ImageFolder(root=validation_dir, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size =12  # Set this to something appropriate for your hardware\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f29bc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "print(f\"Number of batches in train_loader: {len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06e388e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA not available. Using CPU.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f178bfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "# Load the pre-trained DenseNet201 and MobileNetV2 models\n",
    "densenet = models.densenet201(pretrained=True)\n",
    "mobilenet = models.mobilenet_v2(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d976aaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# DenseNet201: Replace classifier with an identity layer to keep features\n",
    "densenet.classifier = torch.nn.Identity()\n",
    "\n",
    "# MobileNetV2: Replace classifier with an identity layer as well\n",
    "mobilenet.classifier = torch.nn.Identity()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d850db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "\n",
    "class CustomClassificationHead(nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(CustomClassificationHead, self).__init__()\n",
    "        # No changes here as this part is not as memory intensive\n",
    "        self.global_avg_pooling = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.batch_norm = nn.BatchNorm1d(num_features)\n",
    "        self.dense1 = nn.Linear(num_features, 512)  # Consider reducing size if necessary\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(512, num_classes)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten the features\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.log_softmax(x)\n",
    "        return x\n",
    "\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        densenet = models.densenet201(pretrained=True)\n",
    "        mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "        \n",
    "        # Remove classification layers\n",
    "        densenet.classifier = nn.Identity()\n",
    "        mobilenet.classifier = nn.Sequential(*list(mobilenet.classifier.children())[:-1], nn.Identity())\n",
    "        \n",
    "        self.densenet = densenet\n",
    "        self.mobilenet = mobilenet\n",
    "        \n",
    "        # Feature reduction layer\n",
    "        self.feature_reduction = nn.Linear(1920 + 1280, 1024)  # Example: Reducing to 1024 features\n",
    "        \n",
    "        # Adjusted classification head for reduced feature size\n",
    "        self.classification_head = CustomClassificationHead(num_features=1024, num_classes=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Using checkpointing for memory efficiency\n",
    "        features_densenet = checkpoint(self.densenet, x)\n",
    "        features_mobilenet = checkpoint(self.mobilenet, x)\n",
    "        \n",
    "        # Concatenate features along the feature dimension\n",
    "        features_combined = torch.cat((features_densenet, features_mobilenet), dim=1)\n",
    "        \n",
    "        # Reduce feature size\n",
    "        reduced_features = self.feature_reduction(features_combined)\n",
    "        \n",
    "        # Forward pass through the classification head\n",
    "        x = self.classification_head(reduced_features)\n",
    "        return x\n",
    "\n",
    "# Initialize the combined model\n",
    "combined_model = CombinedModel()\n",
    "\n",
    "# Assuming 'device' is defined (e.g., cuda or cpu)\n",
    "combined_model=combined_model.to(device)\n",
    "\n",
    "\n",
    "# Example: Pruning 20% of connections in the dense1 layer of the classification head by weight magnitude\n",
    "prune.l1_unstructured(combined_model.classification_head.dense1, name='weight', amount=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4e8735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()  # Clear unused memory\n",
    "\n",
    "inputs, labels = next(iter(train_loader))\n",
    "inputs, labels = inputs.to(device), labels.to(device)\n",
    "outputs = combined_model(inputs)  # Check if this line hangs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71068de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(combined_model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "criterion = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd87489f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    combined_model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} - Training\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = combined_model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    train_accuracy = correct / total\n",
    "    \n",
    "    # Validation phase\n",
    "    combined_model.eval()\n",
    "    valid_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(valid_loader, desc=\"Validating\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = combined_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            valid_loss += loss.item()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    valid_accuracy = correct / total\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Train Loss: {running_loss / len(train_loader):.4f}, \"\n",
    "          f\"Train Acc: {train_accuracy * 100:.2f}%, \"\n",
    "          f\"Valid Loss: {valid_loss / len(valid_loader):.4f}, \"\n",
    "          f\"Valid Acc: {valid_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf86ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
